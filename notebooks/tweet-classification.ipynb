{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Functions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import preprocessor as p\n",
    "import re\n",
    "import demoji \n",
    "import nltk\n",
    "from autocorrect import Speller\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import naive_bayes, svm, metrics, decomposition, ensemble\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Local modules\n",
    "from pipelines import TwitterPipeline\n",
    "from datasets import load_tweets, load_annotated_tweets\n",
    "\n",
    "# Download stopwords package if necessary\n",
    "#nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "spell = Speller()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter Tweets from Wales.....completed in 0:00:00.291668\n",
      "Combine Text fields.....completed in 0:00:00.085749\n",
      "Convert Geo Coordinates (in Floating Point).....completed in 0:00:00.433206\n",
      "Collect BoundingBox Coordinates (GeoJSON).....completed in 0:00:01.478479\n",
      "Collect BoundingBox Coordinates (Tuples).....completed in 0:00:00.245414\n",
      "Match Local Authorities.....completed in 0:00:31.975333\n",
      "Set DateTime Index.....completed in 0:00:22.116583\n"
     ]
    }
   ],
   "source": [
    "# Load the Twitter data\n",
    "tweets = load_tweets()\n",
    "# Filter the tweets from Wales and format the text\n",
    "tweets = TwitterPipeline().apply(tweets.data, verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the annotated tweets, combine them with the tweets\n",
    "annotated = load_annotated_tweets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the annotated dataset\n",
    "df = pd.merge(annotated, tweets, on=\"id_str\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"id_str\", \"text\", \"support_LH\", \"support_ND\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_str</th>\n",
       "      <th>text</th>\n",
       "      <th>support_LH</th>\n",
       "      <th>support_ND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1242070780839636998</td>\n",
       "      <td>Will I [A or B or C] while in isolation?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1242070977321865217</td>\n",
       "      <td>@bbclaurak  an someone ask @BorisJohnson as a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1242070982531088384</td>\n",
       "      <td>Exotic Ebony,Torres style,taking shape.\\n#luth...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1242071279538188288</td>\n",
       "      <td>@miFutureApp Aww. At least on day one of self ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1242071760369078278</td>\n",
       "      <td>For anyone struggling to connect with nature i...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id_str                                               text  \\\n",
       "0  1242070780839636998           Will I [A or B or C] while in isolation?   \n",
       "1  1242070977321865217  @bbclaurak  an someone ask @BorisJohnson as a ...   \n",
       "2  1242070982531088384  Exotic Ebony,Torres style,taking shape.\\n#luth...   \n",
       "3  1242071279538188288  @miFutureApp Aww. At least on day one of self ...   \n",
       "4  1242071760369078278  For anyone struggling to connect with nature i...   \n",
       "\n",
       "  support_LH support_ND  \n",
       "0          0          0  \n",
       "1          0          0  \n",
       "2          0          0  \n",
       "3          0          0  \n",
       "4          2          0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3232, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"text\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2856, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_tweets(text_col: pd.Series):    \n",
    "    \n",
    "    # Make sure every item is a string\n",
    "    text_col = text_col.astype(str)\n",
    "    \n",
    "    # Remove hashtags\n",
    "    text_norm = text_col.apply(lambda x: re.sub(\"#\", \"\", x))\n",
    "    \n",
    "    # Use the tweet preprocesser to remove tweet-specific features from the text\n",
    "    # It also replaces mentions with the word mention, and hashtags with the word hashtag\n",
    "    text_norm = text_norm.apply(lambda tweet: p.tokenize(tweet))\n",
    "    \n",
    "    # Lower case all words\n",
    "    text_norm = text_norm.str.lower()\n",
    "    \n",
    "    # Remove special characters (make sure to run this AFTER lowercasing)\n",
    "    text_norm = text_norm.apply(lambda x: re.sub(\"[^a-z\\s]\", \"\", x))\n",
    "    \n",
    "    # Removing stopwords (using stopword list from NLTK)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text_norm = text_norm.apply(\n",
    "        lambda x: \" \".join(word for word in x.split() if word not in stop_words)\n",
    "    )\n",
    "    \n",
    "#     # Apply spell correcter - Removed due to huge runtime\n",
    "#     text_norm = text_norm.apply(\n",
    "#         lambda x: \" \".join(spell(word) for word in x.split()))\n",
    "    \n",
    "    # Lemmatise the text\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    text_norm = text_norm.apply(\n",
    "        lambda x: \" \".join(lemmatizer.lemmatize(word, pos=\"v\") for word in x.split())\n",
    "    )\n",
    "    \n",
    "    return text_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_norm\"] = normalise_tweets(df[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_str</th>\n",
       "      <th>text</th>\n",
       "      <th>support_LH</th>\n",
       "      <th>support_ND</th>\n",
       "      <th>text_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1242070780839636998</td>\n",
       "      <td>Will I [A or B or C] while in isolation?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>b c isolation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1242070977321865217</td>\n",
       "      <td>@bbclaurak  an someone ask @BorisJohnson as a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mention someone ask mention second case covid ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1242070982531088384</td>\n",
       "      <td>Exotic Ebony,Torres style,taking shape.\\n#luth...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>esmileytic ebonytorres styletaking shape luthi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1242071279538188288</td>\n",
       "      <td>@miFutureApp Aww. At least on day one of self ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mention aww least day one self isolation work ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1242071760369078278</td>\n",
       "      <td>For anyone struggling to connect with nature i...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>anyone struggle connect nature current selfiso...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id_str                                               text  \\\n",
       "0  1242070780839636998           Will I [A or B or C] while in isolation?   \n",
       "1  1242070977321865217  @bbclaurak  an someone ask @BorisJohnson as a ...   \n",
       "2  1242070982531088384  Exotic Ebony,Torres style,taking shape.\\n#luth...   \n",
       "3  1242071279538188288  @miFutureApp Aww. At least on day one of self ...   \n",
       "4  1242071760369078278  For anyone struggling to connect with nature i...   \n",
       "\n",
       "  support_LH support_ND                                          text_norm  \n",
       "0          0          0                                      b c isolation  \n",
       "1          0          0  mention someone ask mention second case covid ...  \n",
       "2          0          0  esmileytic ebonytorres styletaking shape luthi...  \n",
       "3          0          0  mention aww least day one self isolation work ...  \n",
       "4          2          0  anyone struggle connect nature current selfiso...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decide on labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df['support_LH']!=0) & (df['support_ND']!=0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(432, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['support_LH']==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['support_ND']==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df['support_LH']==1) | (df['support_ND']==1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate new column called label\n",
    "df[\"label\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make label based on those entries that LH and ND both agreed might be support related\n",
    "#df[\"label\"].loc[(df['support_LH']!=0) & (df['support_ND']!=0)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2856\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Nina/opt/miniconda3/envs/covid-community/lib/python3.7/site-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# Make label based on those entries that LH and ND both agreed might be support related\n",
    "df[\"label\"].loc[df['support_LH']==1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2424\n",
       "1     432\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up new dataframe\n",
    "df = df[[\"id_str\", \"text_norm\", \"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_str</th>\n",
       "      <th>text_norm</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1242070780839636998</td>\n",
       "      <td>b c isolation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1242070977321865217</td>\n",
       "      <td>mention someone ask mention second case covid ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1242070982531088384</td>\n",
       "      <td>esmileytic ebonytorres styletaking shape luthi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1242071279538188288</td>\n",
       "      <td>mention aww least day one self isolation work ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1242071760369078278</td>\n",
       "      <td>anyone struggle connect nature current selfiso...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id_str                                          text_norm  \\\n",
       "0  1242070780839636998                                      b c isolation   \n",
       "1  1242070977321865217  mention someone ask mention second case covid ...   \n",
       "2  1242070982531088384  esmileytic ebonytorres styletaking shape luthi...   \n",
       "3  1242071279538188288  mention aww least day one self isolation work ...   \n",
       "4  1242071760369078278  anyone struggle connect nature current selfiso...   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now lets start getting ready to train a model..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test/Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('id_str', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"text_norm\"]\n",
    "y = df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train (80%), test (20%) split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=1000)\n",
    "tfidf_vect.fit(df['text_norm'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(X_train)\n",
    "xtest_tfidf =  tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a count vectorizer object for LDA\n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(df['text_norm'])\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  count_vect.transform(X_train)\n",
    "xtest_count =  count_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a LDA Model\n",
    "lda_model = decomposition.LatentDirichletAllocation(n_components=20, learning_method='online', max_iter=20)\n",
    "xtrain_lda = lda_model.fit_transform(xtrain_count)\n",
    "xtest_lda = lda_model.fit_transform(xtest_count)\n",
    "topic_word = lda_model.components_ \n",
    "vocab = count_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature matrix\n",
    "xtest_features = np.concatenate([xtest_tfidf.toarray(), xtest_lda], axis=1)\n",
    "xtrain_features = np.concatenate([xtrain_tfidf.toarray(), xtrain_lda], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB:  0.8513986013986014\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_features, y_train, xtest_features)\n",
    "print (\"NB: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:  0.8479020979020979\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(svm.SVC(), xtrain_features, y_train, xtest_features)\n",
    "print (\"SVM: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:  0.8479020979020979\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(LogisticRegression(), xtrain_features, y_train, xtest_features)\n",
    "print (\"Logistic Regression: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = naive_bayes.MultinomialNB()\n",
    "model.fit(xtrain_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "file_out = \"tweet_classifer.pkl\"\n",
    "pickle.dump(model, open(file_out, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('covid-community': conda)",
   "language": "python",
   "name": "python37764bitcovidcommunitycondad789ed9fffe64e99a915ac5a2eb4ac68"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
